#### - Deixar código maleável para vários modelos - OK

#### - Não só LLMs models mas ChatLLMs também; - OK

#### - Incluir e organizar data; - OK

#### - Pensar na configuração do ambiente com conda; - OK

#### - Configurar git; - OK

#### - Configurar e organizar keys (OpenAI, Google, Anthropic?) - OK

#### - Como vai funcionar o loop? - OK

- modelo e task por vez
- Salvar um arquivo de resultado? Sim. fazendo backup

#### - Criar exemplos de few shot para extract_answer - OK

#### - Revisar text-davinci-003 - OK

#### - Revisar few_shot, questões grandes - OK

#### - Revisar prompts com base nos artigos - OK

#### - Revisar parâmetros dos artigos - OK

#### - TOKENS - OK

#### - Desenvolver novos prompts?

#### - Pensar nos argumentos dos modelos, pré definidos pelas tasks?

- temperature
- k
- context_length
- max_tokens
